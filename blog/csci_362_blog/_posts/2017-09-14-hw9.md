---
layout: post
title: "HW9: Reflections"
description: Considering the future of software engineering using <a href="https://www.infoworld.com/article/3154313/application-development/11-preictions-for-the-future-of-programming.html" target="_blank"><em>11 predictions for the future of programming</em></a>.
date: 2017-09-14 10:00:00 -5EST
category: csci_362_blog
---

&nbsp;&nbsp;&nbsp;&nbsp;To me, the future of programming is both fantastic and scary. On one hand, we're developing tools and systems that enable us to accomplish exponentially more with greater ease than ever. At the same time though, not all of these tools and systems are meant to better the world. In recent years, alongside the rise of such great technologies as the smart phone, VR, and self-driving cars have come equally dangerous pieces of software. Botnets, more complex viruses, large-scale data breaches, and so much more. As we move into the future of programming, we need to look too back to the past to ensure that as we move forward, we fix the mistakes of the past.

&nbsp;&nbsp;&nbsp;&nbsp;Right now in 2017, the IoT has become a rapidly expanding web of devices, APIs, and data. I would imagine that the IoT is still in its infancy in the grand scheme of programming. One day, I would not be surprised to see nearly autonomous home systems, transportation, and tons of other tools for things such as food, entertainment, education, etc. But right now, that future is more of a danger than something to aspire for. The IoT of 2017 is riddled with security risks. Many devices connected to the IoT are improperly maintained (and designed as such), as a result are easily hacked into and used for whatever malevolent purposes a hacker might have. We've gotten lazy over the years. As we build fancy new gadgets, we tend to overlook their security. Default usernames and passwords are a huge part of these security flaws, as well as unprotected communication channels. Even many routers, which have been around for well over a decade now, still rely on default username=username/admin/root password=password/null configurations, and that in itself is a massive danger to simple home computing that has been around for years already. And alongside that, many routers are not properly maintained by their users (ex. updating firmware). Like routers, many of these new, fancy IoT gadgets suffer from the same flaws. They user communication channels with weak protections. They're designed to be simple, but that simplicity just makes it easier for hackers to take control. And just like routers, many IoT devices don't have a process to maintain their firmware and update configuration settings like username and password. If we want to continue building onto the IoT - which is inevitably going to happen - then we need to come up with more user-friendly processes to maintain those devices and keep them secure, rather than leaving them open and vulnerable.

&nbsp;&nbsp;&nbsp;&nbsp;As we move forward into this highly autonomous future, IoT botnets aren't the only problem we face. In a similar way, we're beginning to see a rise in both human-controller and fully autonomous internet bots. Every day when I log into social media sites and view content from public pages, there always seems to be a great deal of what we consider "troll" and "bot" accounts. They post the same, long, reptitive, obnoxious content as comments. They often look human, having somewhat active profiles, real pictures (though often stolen from others), etc., but it's usually easy to tell that they aren't in any way human. Their posts read like a robot - clunky, emotionless cluttered space of random "facts" (whether real or not). These bots have taken over social media sites such as Facebook and Twitter, killing a big part of the human aspect of "social" media. I remember recently reading an article (similar link <a href="http://money.cnn.com/video/technology/culture/2017/08/10/trump-twitter-followers-social-media-bots.cnnmoney/index.html" target="_blank">here</a>) talking about President Donald Trump's twitter account. The author discussed a study done using data from Twitter's API to look at Trump's twitter followers' accounts. From analyzing the profiles following the President's twitter account, they found that an astonishing amount of the accounts appeared to be fake - generally having few to no pictures, few to no posts, and simply reading, again, like robots. These bots tend to share propaganda and falsified or misleading articles, created by many sides of the political spectrum, in order to influence opinions by those who don't know any better. And these accounts are making substantial amounts of money for posting falsified information (see <a href="https://www.washingtonpost.com/news/the-intersect/wp/2016/11/18/this-is-how-the-internets-fake-news-writers-make-money/?utm_term=.b7cbfe9cdbae" target="_blank">here</a>), so they're not going anywhere anytime soon.

&nbsp;&nbsp;&nbsp;&nbsp;These dangers exist whether we like it or not, and we need to plan for them as we move into the future. As more and more systems move to the cloud, they become a liability that we need to protect and secure. The internet has become rampant with bots and malevolent users who seek to hurt others, and it's our responsibility as ethical programmers to work against them. As we build these futuristic systems like autonomous cars, homes, etc., VR, and much more that I'm sure we couldn't even imagine yet, the scope of the damage that these people can cause will become far more substantial. Whereas in the past we had to fight mostly to protect our financial assets, in the future, we may very well be fighting for our very lives. These tools can be very dangerous, and it's our responsibility to keep our users safe.
